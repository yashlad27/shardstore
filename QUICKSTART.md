# ğŸš€ Distributed File Store - Quick Start Guide

A high-performance distributed file storage system with sharding, replication, and versioning.

## âœ¨ Features

- **gRPC API** - High-performance streaming upload/download
- **Consistent Hashing** - Automatic load distribution across nodes
- **Replication** - Configurable replica factor for durability
- **Versioning** - Track and retrieve file versions
- **MongoDB Metadata** - Scalable metadata storage
- **Docker Ready** - Full containerization support

## ğŸ—ï¸ Architecture

```
[ Client ] â”€â”€â–º [ gRPC API Gateway ] â”€â”€â–º [ File Manager ]
                                            â”‚
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â–¼                 â–¼                 â–¼
                    [ Node 1 ]        [ Node 2 ]        [ Node 3 ]
                    (Primary)         (Replica)         (Replica)
                          â”‚
                          â–¼
                  [ MongoDB Metadata ]
```

## ğŸ“¦ Prerequisites

- Go 1.21+
- Docker & Docker Compose
- Protocol Buffers compiler (protoc)

## ğŸš€ Quick Start

### 1. Start MongoDB
```bash
docker-compose up -d mongodb
```

### 2. Build & Run Server
```bash
make build
./bin/server
```

### 3. Use CLI Client

**Upload a file:**
```bash
./bin/client upload /path/to/file.txt
```

**List all files:**
```bash
./bin/client list
```

**Get file info:**
```bash
./bin/client info <file-id>
```

**Download a file:**
```bash
./bin/client download <file-id> output.txt
```

**Delete a file:**
```bash
./bin/client delete <file-id>
```

## ğŸ³ Docker Deployment

**Start all services:**
```bash
docker-compose up -d
```

**View logs:**
```bash
docker-compose logs -f filestore-server
```

**Stop services:**
```bash
docker-compose down
```

## ğŸ§ª Run Tests

```bash
./test.sh
```

## ğŸ“Š Test Results

```
âœ“ Upload - File sharded and replicated across nodes
âœ“ Download - Retrieved from replica with checksum verification
âœ“ List - Metadata retrieved from MongoDB
âœ“ Info - Version tracking working
âœ“ Delete - Cleaned from all replicas
```

## ğŸ› ï¸ Configuration

Environment variables:
- `PORT` - gRPC server port (default: 50051)
- `MONGO_URI` - MongoDB connection string
- `DATABASE` - Database name (default: filestore)

## ğŸ“ Project Structure

```
Distributed_File_Store/
â”œâ”€â”€ api/proto/              # gRPC protocol definitions
â”œâ”€â”€ cmd/
â”‚   â”œâ”€â”€ server/            # Server application
â”‚   â””â”€â”€ client/            # CLI client
â”œâ”€â”€ internal/
â”‚   â”œâ”€â”€ hash/              # Consistent hashing
â”‚   â”œâ”€â”€ manager/           # File management coordinator
â”‚   â”œâ”€â”€ metadata/          # MongoDB operations
â”‚   â”œâ”€â”€ server/            # gRPC server implementation
â”‚   â””â”€â”€ storage/           # Storage node operations
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile
â””â”€â”€ Makefile
```

## ğŸ”§ Development Commands

```bash
make proto          # Generate protobuf code
make build          # Build binaries
make run            # Run server locally
make docker-build   # Build Docker image
make test           # Run tests
make clean          # Clean artifacts
```

## ğŸŒŸ Key Implementation Details

### Consistent Hashing
- 150 virtual nodes per physical node
- MD5-based hash distribution
- Automatic rebalancing on node changes

### Replication
- Configurable replica factor (default: 2)
- Automatic failover on node failure
- SHA-256 checksums for data integrity

### Storage
- File sharding with version control
- Checksum verification on retrieval
- Atomic cleanup on failure

### MongoDB Schema
```javascript
{
  file_id: "uuid",
  filename: "example.txt",
  size: 1024,
  content_type: "text/plain",
  versions: [{
    version_id: "uuid",
    nodes: ["node-1", "node-2"],
    created_at: ISODate()
  }],
  replicas: ["node-1", "node-2"],
  created_at: ISODate(),
  updated_at: ISODate()
}
```

## ğŸ“ˆ Performance

- Streaming uploads/downloads (1MB chunks)
- Concurrent node operations
- Efficient metadata indexing
- gRPC multiplexing

## ğŸ”’ Production Considerations

1. **Security**: Add TLS/mTLS for gRPC
2. **Authentication**: Implement token-based auth
3. **Monitoring**: Add Prometheus metrics
4. **Logging**: Structured logging with levels
5. **Recovery**: Implement automatic node recovery
6. **Scaling**: Deploy storage nodes as separate services

## ğŸ¯ Next Steps

- [ ] Add authentication layer
- [ ] Implement automatic node health checks
- [ ] Add Prometheus metrics
- [ ] Create web UI
- [ ] Add S3-compatible API
- [ ] Implement erasure coding

---

Built with â¤ï¸ using Go, gRPC, and MongoDB
